{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18ab7eae-565a-4e4b-8d6a-8dbed9b9aa1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.19.0-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-2.3.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in e:\\coding_dir\\anaconda\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in e:\\coding_dir\\anaconda\\lib\\site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in e:\\coding_dir\\anaconda\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in e:\\coding_dir\\anaconda\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in e:\\coding_dir\\anaconda\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in e:\\coding_dir\\anaconda\\lib\\site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in e:\\coding_dir\\anaconda\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Using cached grpcio-1.71.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Using cached tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Using cached keras-3.10.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in e:\\coding_dir\\anaconda\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in e:\\coding_dir\\anaconda\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in e:\\coding_dir\\anaconda\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in e:\\coding_dir\\anaconda\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Using cached namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Using cached optree-0.16.0-cp312-cp312-win_amd64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\coding_dir\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\coding_dir\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\coding_dir\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\coding_dir\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in e:\\coding_dir\\anaconda\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in e:\\coding_dir\\anaconda\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in e:\\coding_dir\\anaconda\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in e:\\coding_dir\\anaconda\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\kpska\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in e:\\coding_dir\\anaconda\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Using cached tensorflow-2.19.0-cp312-cp312-win_amd64.whl (376.0 MB)\n",
      "Using cached absl_py-2.3.0-py3-none-any.whl (135 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached grpcio-1.71.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "Using cached keras-3.10.0-py3-none-any.whl (1.4 MB)\n",
      "Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Using cached ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl (210 kB)\n",
      "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Using cached tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "Using cached termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Using cached optree-0.16.0-cp312-cp312-win_amd64.whl (315 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorboard-data-server, optree, opt-einsum, ml-dtypes, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow\n",
      "Successfully installed absl-py-2.3.0 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 keras-3.10.0 libclang-18.1.1 ml-dtypes-0.5.1 namex-0.1.0 opt-einsum-3.4.0 optree-0.16.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 termcolor-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc154c75-e526-4c9d-a32a-5057ffa0165c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gymnasium\n",
      "  Using cached gymnasium-1.1.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: numpy>=1.21.0 in e:\\coding_dir\\anaconda\\lib\\site-packages (from gymnasium) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in e:\\coding_dir\\anaconda\\lib\\site-packages (from gymnasium) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in e:\\coding_dir\\anaconda\\lib\\site-packages (from gymnasium) (4.11.0)\n",
      "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
      "  Using cached Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
      "Using cached gymnasium-1.1.1-py3-none-any.whl (965 kB)\n",
      "Using cached Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Installing collected packages: farama-notifications, gymnasium\n",
      "Successfully installed farama-notifications-0.0.4 gymnasium-1.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ec08605-167e-4036-97d5-adad55a42357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "import gymnasium as gym\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, layers\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "442efdc5-5e35-4fea-a84d-d1710a7a1d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Size:  4\n",
      "Action Size:  2\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "state_size = env.observation_space.shape[0]\n",
    "action_size = env.action_space.n\n",
    "\n",
    "print(\"State Size: \", state_size)\n",
    "print(\"Action Size: \", action_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e917cbd7-6064-48e1-ac4b-da694244dbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(Model):\n",
    "    def __init__(self, action_size, **kwargs):\n",
    "        super(DQN, self).__init__(**kwargs)\n",
    "        self.action_size = action_size\n",
    "        self.d1 = layers.Dense(24, activation='relu', name='d1')\n",
    "        self.d2 = layers.Dense(24, activation='relu', name='d2')\n",
    "        self.d3 = layers.Dense(action_size, activation='linear', name='d3')\n",
    "        # two 24 neurons hidden layer . 4-24-24-2 , output 2 actions\n",
    "    \n",
    "    def call(self, x):\n",
    "        x = self.d1(x)\n",
    "        x = self.d2(x)\n",
    "        return self.d3(x)\n",
    "\n",
    "    # Configs for loading the saved model file later on\n",
    "    def get_config(self):\n",
    "        config = super(DQN, self).get_config()\n",
    "        config.update({\"action_size\": self.action_size})\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6b8b3b5f-ac66-41dc-8ef6-a892b9ada606",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "memory = deque(maxlen=2000)\n",
    "#rolling list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "18a6a28f-560b-4ffc-a5d1-e2cb174c9edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, state_size, action_size, gamma=0.99, epsilon=1.0, epsilon_min=0.01, epsilon_decay=0.995, learning_rate=0.001):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.gamma = gamma #Future reward discount rate\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.model = self._build_model()\n",
    "        self.target_model = self._build_model()\n",
    "        self.update_target_model()\n",
    "\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)\n",
    "\n",
    "    def _build_model(self):\n",
    "        return DQN(self.action_size) # build a model using DQN Class\n",
    "\n",
    "    def update_target_model(self):\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        memory.append((state, action, reward, next_state, done)) #stacking\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size) # if epsilon is high choose a random value from range , in this case 1 or 2 else use DQN to find Q value\n",
    "        q_values = self.model(np.array([state])) \n",
    "        return np.argmax(q_values[0].numpy()) \n",
    "\n",
    "    def save_model(self, filepath):\n",
    "        self.model.save(filepath)\n",
    "\n",
    "    def load_model(self, filepath):\n",
    "        # Load the saved model from the specified filepath\n",
    "        self.model = tf.keras.models.load_model(filepath, custom_objects={\"DQN\": DQN})\n",
    "        self.target_model = tf.keras.models.load_model(filepath, custom_objects={\"DQN\": DQN})\n",
    "        \n",
    "    def replay(self, batch_size):\n",
    "        minibatch = random.sample(memory, batch_size)\n",
    "        for state, action, reward, next_state, done in minibatch:\n",
    "            with tf.GradientTape() as tape:\n",
    "                q_values = self.model(np.array([state]), training=True)\n",
    "                q_value = q_values[0][action]\n",
    "\n",
    "                if done:\n",
    "                    target = reward\n",
    "                else:\n",
    "                    next_action = np.argmax(self.model(np.array([next_state]))[0].numpy())\n",
    "                    t = self.target_model(np.array([next_state]))[0][next_action]\n",
    "                    target = reward + self.gamma * t \n",
    "\n",
    "                loss = tf.reduce_mean(tf.square(target - q_value))\n",
    "\n",
    "            grads = tape.gradient(loss, self.model.trainable_variables)\n",
    "            self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b90f8335-5bd0-4d86-97b0-b90102ae3b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32           # Number of samples for training\n",
    "n_episodes = 500          # Total number of episodes to train on\n",
    "gamma = 0.95              # Discount factor for future rewards (0 to 1)\n",
    "epsilon = 1.0             # Initial exploration rate \n",
    "epsilon_min = 0.01        # Minimum exploration rate\n",
    "epsilon_decay = 0.995     # Decay factor for epsilon after each episode\n",
    "learning_rate = 0.001     # Step size for neural network weight updates\n",
    "update_target_every = 5   # Number of episodes between target network updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bf6b0727-159b-481e-adce-ac51ec151814",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0/500, Score: 18, Epsilon: 1.00\n",
      "Episode: 1/500, Score: 9, Epsilon: 0.99\n",
      "Episode: 2/500, Score: 28, Epsilon: 0.99\n",
      "Episode: 3/500, Score: 17, Epsilon: 0.99\n",
      "Episode: 4/500, Score: 15, Epsilon: 0.98\n",
      "Episode: 5/500, Score: 11, Epsilon: 0.98\n",
      "Episode: 6/500, Score: 20, Epsilon: 0.97\n",
      "Episode: 7/500, Score: 21, Epsilon: 0.97\n",
      "Episode: 8/500, Score: 11, Epsilon: 0.96\n",
      "Episode: 9/500, Score: 19, Epsilon: 0.96\n",
      "Episode: 10/500, Score: 9, Epsilon: 0.95\n",
      "Episode: 11/500, Score: 9, Epsilon: 0.95\n",
      "Episode: 12/500, Score: 8, Epsilon: 0.94\n",
      "Episode: 13/500, Score: 18, Epsilon: 0.94\n",
      "Episode: 14/500, Score: 31, Epsilon: 0.93\n",
      "Episode: 15/500, Score: 12, Epsilon: 0.93\n",
      "Episode: 16/500, Score: 14, Epsilon: 0.92\n",
      "Episode: 17/500, Score: 21, Epsilon: 0.92\n",
      "Episode: 18/500, Score: 11, Epsilon: 0.91\n",
      "Episode: 19/500, Score: 36, Epsilon: 0.91\n",
      "Episode: 20/500, Score: 33, Epsilon: 0.90\n",
      "Episode: 21/500, Score: 26, Epsilon: 0.90\n",
      "Episode: 22/500, Score: 14, Epsilon: 0.90\n",
      "Episode: 23/500, Score: 11, Epsilon: 0.89\n",
      "Episode: 24/500, Score: 24, Epsilon: 0.89\n",
      "Episode: 25/500, Score: 18, Epsilon: 0.88\n",
      "Episode: 26/500, Score: 13, Epsilon: 0.88\n",
      "Episode: 27/500, Score: 9, Epsilon: 0.87\n",
      "Episode: 28/500, Score: 37, Epsilon: 0.87\n",
      "Episode: 29/500, Score: 19, Epsilon: 0.86\n",
      "Episode: 30/500, Score: 12, Epsilon: 0.86\n",
      "Episode: 31/500, Score: 18, Epsilon: 0.86\n",
      "Episode: 32/500, Score: 28, Epsilon: 0.85\n",
      "Episode: 33/500, Score: 18, Epsilon: 0.85\n",
      "Episode: 34/500, Score: 12, Epsilon: 0.84\n",
      "Episode: 35/500, Score: 11, Epsilon: 0.84\n",
      "Episode: 36/500, Score: 26, Epsilon: 0.83\n",
      "Episode: 37/500, Score: 14, Epsilon: 0.83\n",
      "Episode: 38/500, Score: 12, Epsilon: 0.83\n",
      "Episode: 39/500, Score: 20, Epsilon: 0.82\n",
      "Episode: 40/500, Score: 16, Epsilon: 0.82\n",
      "Episode: 41/500, Score: 15, Epsilon: 0.81\n",
      "Episode: 42/500, Score: 19, Epsilon: 0.81\n",
      "Episode: 43/500, Score: 10, Epsilon: 0.81\n",
      "Episode: 44/500, Score: 23, Epsilon: 0.80\n",
      "Episode: 45/500, Score: 15, Epsilon: 0.80\n",
      "Episode: 46/500, Score: 11, Epsilon: 0.79\n",
      "Episode: 47/500, Score: 18, Epsilon: 0.79\n",
      "Episode: 48/500, Score: 16, Epsilon: 0.79\n",
      "Episode: 49/500, Score: 11, Epsilon: 0.78\n",
      "Episode: 50/500, Score: 12, Epsilon: 0.78\n",
      "Episode: 51/500, Score: 23, Epsilon: 0.77\n",
      "Episode: 52/500, Score: 15, Epsilon: 0.77\n",
      "Episode: 53/500, Score: 11, Epsilon: 0.77\n",
      "Episode: 54/500, Score: 36, Epsilon: 0.76\n",
      "Episode: 55/500, Score: 15, Epsilon: 0.76\n",
      "Episode: 56/500, Score: 51, Epsilon: 0.76\n",
      "Episode: 57/500, Score: 18, Epsilon: 0.75\n",
      "Episode: 58/500, Score: 18, Epsilon: 0.75\n",
      "Episode: 59/500, Score: 16, Epsilon: 0.74\n",
      "Episode: 60/500, Score: 19, Epsilon: 0.74\n",
      "Episode: 61/500, Score: 14, Epsilon: 0.74\n",
      "Episode: 62/500, Score: 11, Epsilon: 0.73\n",
      "Episode: 63/500, Score: 21, Epsilon: 0.73\n",
      "Episode: 64/500, Score: 19, Epsilon: 0.73\n",
      "Episode: 65/500, Score: 21, Epsilon: 0.72\n",
      "Episode: 66/500, Score: 13, Epsilon: 0.72\n",
      "Episode: 67/500, Score: 22, Epsilon: 0.71\n",
      "Episode: 68/500, Score: 20, Epsilon: 0.71\n",
      "Episode: 69/500, Score: 14, Epsilon: 0.71\n",
      "Episode: 70/500, Score: 16, Epsilon: 0.70\n",
      "Episode: 71/500, Score: 12, Epsilon: 0.70\n",
      "Episode: 72/500, Score: 13, Epsilon: 0.70\n",
      "Episode: 73/500, Score: 26, Epsilon: 0.69\n",
      "Episode: 74/500, Score: 25, Epsilon: 0.69\n",
      "Episode: 75/500, Score: 23, Epsilon: 0.69\n",
      "Episode: 76/500, Score: 25, Epsilon: 0.68\n",
      "Episode: 77/500, Score: 36, Epsilon: 0.68\n",
      "Episode: 78/500, Score: 13, Epsilon: 0.68\n",
      "Episode: 79/500, Score: 23, Epsilon: 0.67\n",
      "Episode: 80/500, Score: 19, Epsilon: 0.67\n",
      "Episode: 81/500, Score: 21, Epsilon: 0.67\n",
      "Episode: 82/500, Score: 15, Epsilon: 0.66\n",
      "Episode: 83/500, Score: 27, Epsilon: 0.66\n",
      "Episode: 84/500, Score: 13, Epsilon: 0.66\n",
      "Episode: 85/500, Score: 22, Epsilon: 0.65\n",
      "Episode: 86/500, Score: 48, Epsilon: 0.65\n",
      "Episode: 87/500, Score: 16, Epsilon: 0.65\n",
      "Episode: 88/500, Score: 29, Epsilon: 0.64\n",
      "Episode: 89/500, Score: 22, Epsilon: 0.64\n",
      "Episode: 90/500, Score: 30, Epsilon: 0.64\n",
      "Episode: 91/500, Score: 16, Epsilon: 0.63\n",
      "Episode: 92/500, Score: 18, Epsilon: 0.63\n",
      "Episode: 93/500, Score: 28, Epsilon: 0.63\n",
      "Episode: 94/500, Score: 12, Epsilon: 0.62\n",
      "Episode: 95/500, Score: 54, Epsilon: 0.62\n",
      "Episode: 96/500, Score: 38, Epsilon: 0.62\n",
      "Episode: 97/500, Score: 22, Epsilon: 0.61\n",
      "Episode: 98/500, Score: 14, Epsilon: 0.61\n",
      "Episode: 99/500, Score: 19, Epsilon: 0.61\n",
      "Episode: 100/500, Score: 14, Epsilon: 0.61\n",
      "Episode: 101/500, Score: 80, Epsilon: 0.60\n",
      "Episode: 102/500, Score: 102, Epsilon: 0.60\n",
      "Episode: 103/500, Score: 11, Epsilon: 0.60\n",
      "Episode: 104/500, Score: 13, Epsilon: 0.59\n",
      "Episode: 105/500, Score: 35, Epsilon: 0.59\n",
      "Episode: 106/500, Score: 23, Epsilon: 0.59\n",
      "Episode: 107/500, Score: 17, Epsilon: 0.58\n",
      "Episode: 108/500, Score: 9, Epsilon: 0.58\n",
      "Episode: 109/500, Score: 27, Epsilon: 0.58\n",
      "Episode: 110/500, Score: 100, Epsilon: 0.58\n",
      "Episode: 111/500, Score: 24, Epsilon: 0.57\n",
      "Episode: 112/500, Score: 16, Epsilon: 0.57\n",
      "Episode: 113/500, Score: 12, Epsilon: 0.57\n",
      "Episode: 114/500, Score: 40, Epsilon: 0.56\n",
      "Episode: 115/500, Score: 122, Epsilon: 0.56\n",
      "Episode: 116/500, Score: 16, Epsilon: 0.56\n",
      "Episode: 117/500, Score: 49, Epsilon: 0.56\n",
      "Episode: 118/500, Score: 28, Epsilon: 0.55\n",
      "Episode: 119/500, Score: 25, Epsilon: 0.55\n",
      "Episode: 120/500, Score: 10, Epsilon: 0.55\n",
      "Episode: 121/500, Score: 30, Epsilon: 0.55\n",
      "Episode: 122/500, Score: 25, Epsilon: 0.54\n",
      "Episode: 123/500, Score: 20, Epsilon: 0.54\n",
      "Episode: 124/500, Score: 23, Epsilon: 0.54\n",
      "Episode: 125/500, Score: 19, Epsilon: 0.53\n",
      "Episode: 126/500, Score: 33, Epsilon: 0.53\n",
      "Episode: 127/500, Score: 11, Epsilon: 0.53\n",
      "Episode: 128/500, Score: 31, Epsilon: 0.53\n",
      "Episode: 129/500, Score: 15, Epsilon: 0.52\n",
      "Episode: 130/500, Score: 14, Epsilon: 0.52\n",
      "Episode: 131/500, Score: 28, Epsilon: 0.52\n",
      "Episode: 132/500, Score: 32, Epsilon: 0.52\n",
      "Episode: 133/500, Score: 31, Epsilon: 0.51\n",
      "Episode: 134/500, Score: 79, Epsilon: 0.51\n",
      "Episode: 135/500, Score: 52, Epsilon: 0.51\n",
      "Episode: 136/500, Score: 13, Epsilon: 0.51\n",
      "Episode: 137/500, Score: 21, Epsilon: 0.50\n",
      "Episode: 138/500, Score: 12, Epsilon: 0.50\n",
      "Episode: 139/500, Score: 108, Epsilon: 0.50\n",
      "Episode: 140/500, Score: 26, Epsilon: 0.50\n",
      "Episode: 141/500, Score: 21, Epsilon: 0.49\n",
      "Episode: 142/500, Score: 32, Epsilon: 0.49\n",
      "Episode: 143/500, Score: 71, Epsilon: 0.49\n",
      "Episode: 144/500, Score: 79, Epsilon: 0.49\n",
      "Episode: 145/500, Score: 16, Epsilon: 0.48\n",
      "Episode: 146/500, Score: 70, Epsilon: 0.48\n",
      "Episode: 147/500, Score: 32, Epsilon: 0.48\n",
      "Episode: 148/500, Score: 59, Epsilon: 0.48\n",
      "Episode: 149/500, Score: 41, Epsilon: 0.47\n",
      "Episode: 150/500, Score: 36, Epsilon: 0.47\n",
      "Episode: 151/500, Score: 16, Epsilon: 0.47\n",
      "Episode: 152/500, Score: 42, Epsilon: 0.47\n",
      "Episode: 153/500, Score: 54, Epsilon: 0.46\n",
      "Episode: 154/500, Score: 115, Epsilon: 0.46\n",
      "Episode: 155/500, Score: 99, Epsilon: 0.46\n",
      "Episode: 156/500, Score: 47, Epsilon: 0.46\n",
      "Episode: 157/500, Score: 44, Epsilon: 0.46\n",
      "Episode: 158/500, Score: 110, Epsilon: 0.45\n",
      "Episode: 159/500, Score: 101, Epsilon: 0.45\n",
      "Episode: 160/500, Score: 11, Epsilon: 0.45\n",
      "Episode: 161/500, Score: 50, Epsilon: 0.45\n",
      "Episode: 162/500, Score: 32, Epsilon: 0.44\n",
      "Episode: 163/500, Score: 311, Epsilon: 0.44\n",
      "Episode: 164/500, Score: 51, Epsilon: 0.44\n",
      "Episode: 165/500, Score: 345, Epsilon: 0.44\n",
      "Episode: 166/500, Score: 89, Epsilon: 0.44\n",
      "Episode: 167/500, Score: 26, Epsilon: 0.43\n",
      "Episode: 168/500, Score: 118, Epsilon: 0.43\n",
      "Episode: 169/500, Score: 18, Epsilon: 0.43\n",
      "Episode: 170/500, Score: 148, Epsilon: 0.43\n",
      "Episode: 171/500, Score: 130, Epsilon: 0.42\n",
      "Episode: 172/500, Score: 138, Epsilon: 0.42\n",
      "Episode: 173/500, Score: 182, Epsilon: 0.42\n",
      "Episode: 174/500, Score: 27, Epsilon: 0.42\n",
      "Episode: 175/500, Score: 95, Epsilon: 0.42\n",
      "Episode: 176/500, Score: 55, Epsilon: 0.41\n",
      "Episode: 177/500, Score: 70, Epsilon: 0.41\n",
      "Episode: 178/500, Score: 15, Epsilon: 0.41\n",
      "Episode: 179/500, Score: 110, Epsilon: 0.41\n",
      "Episode: 180/500, Score: 95, Epsilon: 0.41\n",
      "Episode: 181/500, Score: 22, Epsilon: 0.40\n",
      "Episode: 182/500, Score: 104, Epsilon: 0.40\n",
      "Episode: 183/500, Score: 78, Epsilon: 0.40\n",
      "Episode: 184/500, Score: 85, Epsilon: 0.40\n",
      "Episode: 185/500, Score: 101, Epsilon: 0.40\n",
      "Episode: 186/500, Score: 63, Epsilon: 0.39\n",
      "Episode: 187/500, Score: 16, Epsilon: 0.39\n",
      "Episode: 188/500, Score: 133, Epsilon: 0.39\n",
      "Episode: 189/500, Score: 14, Epsilon: 0.39\n",
      "Episode: 190/500, Score: 23, Epsilon: 0.39\n",
      "Episode: 191/500, Score: 142, Epsilon: 0.38\n",
      "Episode: 192/500, Score: 158, Epsilon: 0.38\n",
      "Episode: 193/500, Score: 288, Epsilon: 0.38\n",
      "Episode: 194/500, Score: 110, Epsilon: 0.38\n",
      "Episode: 195/500, Score: 188, Epsilon: 0.38\n",
      "Episode: 196/500, Score: 144, Epsilon: 0.37\n",
      "Episode: 197/500, Score: 30, Epsilon: 0.37\n",
      "Episode: 198/500, Score: 102, Epsilon: 0.37\n",
      "Episode: 199/500, Score: 141, Epsilon: 0.37\n",
      "Episode: 200/500, Score: 166, Epsilon: 0.37\n",
      "Episode: 201/500, Score: 99, Epsilon: 0.37\n",
      "Episode: 202/500, Score: 63, Epsilon: 0.36\n",
      "Episode: 203/500, Score: 228, Epsilon: 0.36\n",
      "Episode: 204/500, Score: 93, Epsilon: 0.36\n",
      "Episode: 205/500, Score: 225, Epsilon: 0.36\n",
      "Episode: 206/500, Score: 207, Epsilon: 0.36\n",
      "Episode: 207/500, Score: 192, Epsilon: 0.35\n",
      "Episode: 208/500, Score: 114, Epsilon: 0.35\n",
      "Episode: 209/500, Score: 126, Epsilon: 0.35\n",
      "Episode: 210/500, Score: 94, Epsilon: 0.35\n",
      "Episode: 211/500, Score: 72, Epsilon: 0.35\n",
      "Episode: 212/500, Score: 142, Epsilon: 0.35\n",
      "Episode: 213/500, Score: 25, Epsilon: 0.34\n",
      "Episode: 214/500, Score: 13, Epsilon: 0.34\n",
      "Episode: 215/500, Score: 131, Epsilon: 0.34\n",
      "Episode: 216/500, Score: 100, Epsilon: 0.34\n",
      "Episode: 217/500, Score: 138, Epsilon: 0.34\n",
      "Episode: 218/500, Score: 160, Epsilon: 0.34\n",
      "Episode: 219/500, Score: 161, Epsilon: 0.33\n",
      "Episode: 220/500, Score: 197, Epsilon: 0.33\n",
      "Episode: 221/500, Score: 132, Epsilon: 0.33\n",
      "Episode: 222/500, Score: 139, Epsilon: 0.33\n",
      "Episode: 223/500, Score: 89, Epsilon: 0.33\n",
      "Episode: 224/500, Score: 104, Epsilon: 0.33\n",
      "Episode: 225/500, Score: 123, Epsilon: 0.32\n",
      "Episode: 226/500, Score: 109, Epsilon: 0.32\n",
      "Episode: 227/500, Score: 158, Epsilon: 0.32\n",
      "Episode: 228/500, Score: 161, Epsilon: 0.32\n",
      "Episode: 229/500, Score: 112, Epsilon: 0.32\n",
      "Episode: 230/500, Score: 130, Epsilon: 0.32\n",
      "Episode: 231/500, Score: 118, Epsilon: 0.31\n",
      "Episode: 232/500, Score: 301, Epsilon: 0.31\n",
      "Episode: 233/500, Score: 251, Epsilon: 0.31\n",
      "Episode: 234/500, Score: 340, Epsilon: 0.31\n",
      "Episode: 235/500, Score: 144, Epsilon: 0.31\n",
      "Episode: 236/500, Score: 148, Epsilon: 0.31\n",
      "Episode: 237/500, Score: 9, Epsilon: 0.30\n",
      "Episode: 238/500, Score: 10, Epsilon: 0.30\n",
      "Episode: 239/500, Score: 111, Epsilon: 0.30\n",
      "Episode: 240/500, Score: 129, Epsilon: 0.30\n",
      "Episode: 241/500, Score: 180, Epsilon: 0.30\n",
      "Episode: 242/500, Score: 242, Epsilon: 0.30\n",
      "Episode: 243/500, Score: 159, Epsilon: 0.30\n",
      "Episode: 244/500, Score: 105, Epsilon: 0.29\n",
      "Episode: 245/500, Score: 213, Epsilon: 0.29\n",
      "Episode: 246/500, Score: 114, Epsilon: 0.29\n",
      "Episode: 247/500, Score: 188, Epsilon: 0.29\n",
      "Episode: 248/500, Score: 24, Epsilon: 0.29\n",
      "Episode: 249/500, Score: 165, Epsilon: 0.29\n",
      "Episode: 250/500, Score: 289, Epsilon: 0.29\n",
      "Episode: 251/500, Score: 158, Epsilon: 0.28\n",
      "Episode: 252/500, Score: 107, Epsilon: 0.28\n",
      "Episode: 253/500, Score: 127, Epsilon: 0.28\n",
      "Episode: 254/500, Score: 135, Epsilon: 0.28\n",
      "Episode: 255/500, Score: 129, Epsilon: 0.28\n",
      "Episode: 256/500, Score: 10, Epsilon: 0.28\n",
      "Episode: 257/500, Score: 19, Epsilon: 0.28\n",
      "Episode: 258/500, Score: 14, Epsilon: 0.27\n",
      "Episode: 259/500, Score: 9, Epsilon: 0.27\n",
      "Episode: 260/500, Score: 10, Epsilon: 0.27\n",
      "Episode: 261/500, Score: 83, Epsilon: 0.27\n",
      "Episode: 262/500, Score: 14, Epsilon: 0.27\n",
      "Episode: 263/500, Score: 15, Epsilon: 0.27\n",
      "Episode: 264/500, Score: 14, Epsilon: 0.27\n",
      "Episode: 265/500, Score: 16, Epsilon: 0.26\n",
      "Episode: 266/500, Score: 9, Epsilon: 0.26\n",
      "Episode: 267/500, Score: 18, Epsilon: 0.26\n",
      "Episode: 268/500, Score: 11, Epsilon: 0.26\n",
      "Episode: 269/500, Score: 19, Epsilon: 0.26\n",
      "Episode: 270/500, Score: 15, Epsilon: 0.26\n",
      "Episode: 271/500, Score: 19, Epsilon: 0.26\n",
      "Episode: 272/500, Score: 21, Epsilon: 0.26\n",
      "Episode: 273/500, Score: 9, Epsilon: 0.25\n",
      "Episode: 274/500, Score: 25, Epsilon: 0.25\n",
      "Episode: 275/500, Score: 7, Epsilon: 0.25\n",
      "Episode: 276/500, Score: 18, Epsilon: 0.25\n",
      "Episode: 277/500, Score: 19, Epsilon: 0.25\n",
      "Episode: 278/500, Score: 14, Epsilon: 0.25\n",
      "Episode: 279/500, Score: 18, Epsilon: 0.25\n",
      "Episode: 280/500, Score: 26, Epsilon: 0.25\n",
      "Episode: 281/500, Score: 10, Epsilon: 0.24\n",
      "Episode: 282/500, Score: 31, Epsilon: 0.24\n",
      "Episode: 283/500, Score: 20, Epsilon: 0.24\n",
      "Episode: 284/500, Score: 26, Epsilon: 0.24\n",
      "Episode: 285/500, Score: 14, Epsilon: 0.24\n",
      "Episode: 286/500, Score: 103, Epsilon: 0.24\n",
      "Episode: 287/500, Score: 36, Epsilon: 0.24\n",
      "Episode: 288/500, Score: 113, Epsilon: 0.24\n",
      "Episode: 289/500, Score: 47, Epsilon: 0.23\n",
      "Episode: 290/500, Score: 11, Epsilon: 0.23\n",
      "Episode: 291/500, Score: 25, Epsilon: 0.23\n",
      "Episode: 292/500, Score: 40, Epsilon: 0.23\n",
      "Episode: 293/500, Score: 83, Epsilon: 0.23\n",
      "Episode: 294/500, Score: 16, Epsilon: 0.23\n",
      "Episode: 295/500, Score: 84, Epsilon: 0.23\n",
      "Episode: 296/500, Score: 40, Epsilon: 0.23\n",
      "Episode: 297/500, Score: 10, Epsilon: 0.23\n",
      "Episode: 298/500, Score: 178, Epsilon: 0.22\n",
      "Episode: 299/500, Score: 499, Epsilon: 0.22\n",
      "Episode: 300/500, Score: 68, Epsilon: 0.22\n",
      "Episode: 301/500, Score: 459, Epsilon: 0.22\n",
      "Episode: 302/500, Score: 76, Epsilon: 0.22\n",
      "Episode: 303/500, Score: 110, Epsilon: 0.22\n",
      "Episode: 304/500, Score: 53, Epsilon: 0.22\n",
      "Episode: 305/500, Score: 68, Epsilon: 0.22\n",
      "Episode: 306/500, Score: 22, Epsilon: 0.22\n",
      "Episode: 307/500, Score: 36, Epsilon: 0.21\n",
      "Episode: 308/500, Score: 20, Epsilon: 0.21\n",
      "Episode: 309/500, Score: 63, Epsilon: 0.21\n",
      "Episode: 310/500, Score: 66, Epsilon: 0.21\n",
      "Episode: 311/500, Score: 14, Epsilon: 0.21\n",
      "Episode: 312/500, Score: 47, Epsilon: 0.21\n",
      "Episode: 313/500, Score: 66, Epsilon: 0.21\n",
      "Episode: 314/500, Score: 97, Epsilon: 0.21\n",
      "Episode: 315/500, Score: 84, Epsilon: 0.21\n",
      "Episode: 316/500, Score: 98, Epsilon: 0.21\n",
      "Episode: 317/500, Score: 104, Epsilon: 0.20\n",
      "Episode: 318/500, Score: 147, Epsilon: 0.20\n",
      "Episode: 319/500, Score: 91, Epsilon: 0.20\n",
      "Episode: 320/500, Score: 147, Epsilon: 0.20\n",
      "Episode: 321/500, Score: 122, Epsilon: 0.20\n",
      "Episode: 322/500, Score: 130, Epsilon: 0.20\n",
      "Episode: 323/500, Score: 9, Epsilon: 0.20\n",
      "Episode: 324/500, Score: 124, Epsilon: 0.20\n",
      "Episode: 325/500, Score: 88, Epsilon: 0.20\n",
      "Episode: 326/500, Score: 123, Epsilon: 0.20\n",
      "Episode: 327/500, Score: 120, Epsilon: 0.19\n",
      "Episode: 328/500, Score: 92, Epsilon: 0.19\n",
      "Episode: 329/500, Score: 94, Epsilon: 0.19\n",
      "Episode: 330/500, Score: 102, Epsilon: 0.19\n",
      "Episode: 331/500, Score: 80, Epsilon: 0.19\n",
      "Episode: 332/500, Score: 16, Epsilon: 0.19\n",
      "Episode: 333/500, Score: 123, Epsilon: 0.19\n",
      "Episode: 334/500, Score: 86, Epsilon: 0.19\n",
      "Episode: 335/500, Score: 129, Epsilon: 0.19\n",
      "Episode: 336/500, Score: 163, Epsilon: 0.19\n",
      "Episode: 337/500, Score: 95, Epsilon: 0.18\n",
      "Episode: 338/500, Score: 147, Epsilon: 0.18\n",
      "Episode: 339/500, Score: 422, Epsilon: 0.18\n",
      "Episode: 340/500, Score: 181, Epsilon: 0.18\n",
      "Episode: 341/500, Score: 155, Epsilon: 0.18\n",
      "Episode: 342/500, Score: 312, Epsilon: 0.18\n",
      "Episode: 343/500, Score: 19, Epsilon: 0.18\n",
      "Episode: 344/500, Score: 77, Epsilon: 0.18\n",
      "Episode: 345/500, Score: 96, Epsilon: 0.18\n",
      "Episode: 346/500, Score: 11, Epsilon: 0.18\n",
      "Episode: 347/500, Score: 43, Epsilon: 0.18\n",
      "Episode: 348/500, Score: 131, Epsilon: 0.17\n",
      "Episode: 349/500, Score: 11, Epsilon: 0.17\n",
      "Episode: 350/500, Score: 124, Epsilon: 0.17\n",
      "Episode: 351/500, Score: 116, Epsilon: 0.17\n",
      "Episode: 352/500, Score: 113, Epsilon: 0.17\n",
      "Episode: 353/500, Score: 159, Epsilon: 0.17\n",
      "Episode: 354/500, Score: 77, Epsilon: 0.17\n",
      "Episode: 355/500, Score: 12, Epsilon: 0.17\n",
      "Episode: 356/500, Score: 93, Epsilon: 0.17\n",
      "Episode: 357/500, Score: 114, Epsilon: 0.17\n",
      "Episode: 358/500, Score: 90, Epsilon: 0.17\n",
      "Episode: 359/500, Score: 237, Epsilon: 0.17\n",
      "Episode: 360/500, Score: 194, Epsilon: 0.16\n",
      "Episode: 361/500, Score: 323, Epsilon: 0.16\n",
      "Episode: 362/500, Score: 120, Epsilon: 0.16\n",
      "Episode: 363/500, Score: 207, Epsilon: 0.16\n",
      "Episode: 364/500, Score: 127, Epsilon: 0.16\n",
      "Episode: 365/500, Score: 186, Epsilon: 0.16\n",
      "Episode: 366/500, Score: 279, Epsilon: 0.16\n",
      "Episode: 367/500, Score: 182, Epsilon: 0.16\n",
      "Episode: 368/500, Score: 160, Epsilon: 0.16\n",
      "Episode: 369/500, Score: 137, Epsilon: 0.16\n",
      "Episode: 370/500, Score: 238, Epsilon: 0.16\n",
      "Episode: 371/500, Score: 163, Epsilon: 0.16\n",
      "Episode: 372/500, Score: 156, Epsilon: 0.15\n",
      "Episode: 373/500, Score: 202, Epsilon: 0.15\n",
      "Episode: 374/500, Score: 155, Epsilon: 0.15\n",
      "Episode: 375/500, Score: 264, Epsilon: 0.15\n",
      "Episode: 376/500, Score: 146, Epsilon: 0.15\n",
      "Episode: 377/500, Score: 319, Epsilon: 0.15\n",
      "Episode: 378/500, Score: 11, Epsilon: 0.15\n",
      "Episode: 379/500, Score: 120, Epsilon: 0.15\n",
      "Episode: 380/500, Score: 154, Epsilon: 0.15\n",
      "Episode: 381/500, Score: 139, Epsilon: 0.15\n",
      "Episode: 382/500, Score: 219, Epsilon: 0.15\n",
      "Episode: 383/500, Score: 131, Epsilon: 0.15\n",
      "Episode: 384/500, Score: 113, Epsilon: 0.15\n",
      "Episode: 385/500, Score: 254, Epsilon: 0.15\n",
      "Episode: 386/500, Score: 183, Epsilon: 0.14\n",
      "Episode: 387/500, Score: 197, Epsilon: 0.14\n",
      "Episode: 388/500, Score: 249, Epsilon: 0.14\n",
      "Episode: 389/500, Score: 200, Epsilon: 0.14\n",
      "Episode: 390/500, Score: 188, Epsilon: 0.14\n",
      "Episode: 391/500, Score: 138, Epsilon: 0.14\n",
      "Episode: 392/500, Score: 491, Epsilon: 0.14\n",
      "Episode: 393/500, Score: 190, Epsilon: 0.14\n",
      "Episode: 394/500, Score: 175, Epsilon: 0.14\n",
      "Episode: 395/500, Score: 300, Epsilon: 0.14\n",
      "Episode: 396/500, Score: 225, Epsilon: 0.14\n",
      "Episode: 397/500, Score: 197, Epsilon: 0.14\n",
      "Episode: 398/500, Score: 275, Epsilon: 0.14\n",
      "Episode: 399/500, Score: 187, Epsilon: 0.14\n",
      "Episode: 400/500, Score: 270, Epsilon: 0.13\n",
      "Episode: 401/500, Score: 408, Epsilon: 0.13\n",
      "Episode: 402/500, Score: 138, Epsilon: 0.13\n",
      "Episode: 403/500, Score: 482, Epsilon: 0.13\n",
      "Episode: 404/500, Score: 100, Epsilon: 0.13\n",
      "Episode: 405/500, Score: 187, Epsilon: 0.13\n",
      "Episode: 406/500, Score: 18, Epsilon: 0.13\n",
      "Episode: 407/500, Score: 368, Epsilon: 0.13\n",
      "Episode: 408/500, Score: 101, Epsilon: 0.13\n",
      "Episode: 409/500, Score: 109, Epsilon: 0.13\n",
      "Episode: 410/500, Score: 173, Epsilon: 0.13\n",
      "Episode: 411/500, Score: 213, Epsilon: 0.13\n",
      "Episode: 412/500, Score: 190, Epsilon: 0.13\n",
      "Episode: 413/500, Score: 122, Epsilon: 0.13\n",
      "Episode: 414/500, Score: 168, Epsilon: 0.13\n",
      "Episode: 415/500, Score: 236, Epsilon: 0.12\n",
      "Episode: 416/500, Score: 9, Epsilon: 0.12\n",
      "Episode: 417/500, Score: 256, Epsilon: 0.12\n",
      "Episode: 418/500, Score: 219, Epsilon: 0.12\n",
      "Episode: 419/500, Score: 11, Epsilon: 0.12\n",
      "Episode: 420/500, Score: 236, Epsilon: 0.12\n",
      "Episode: 421/500, Score: 11, Epsilon: 0.12\n",
      "Episode: 422/500, Score: 118, Epsilon: 0.12\n",
      "Episode: 423/500, Score: 451, Epsilon: 0.12\n",
      "Episode: 424/500, Score: 10, Epsilon: 0.12\n",
      "Episode: 425/500, Score: 224, Epsilon: 0.12\n",
      "Episode: 426/500, Score: 10, Epsilon: 0.12\n",
      "Episode: 427/500, Score: 238, Epsilon: 0.12\n",
      "Episode: 428/500, Score: 11, Epsilon: 0.12\n",
      "Episode: 429/500, Score: 10, Epsilon: 0.12\n",
      "Episode: 430/500, Score: 11, Epsilon: 0.12\n",
      "Episode: 431/500, Score: 499, Epsilon: 0.12\n",
      "Episode: 432/500, Score: 8, Epsilon: 0.11\n",
      "Episode: 433/500, Score: 102, Epsilon: 0.11\n",
      "Episode: 434/500, Score: 98, Epsilon: 0.11\n",
      "Episode: 435/500, Score: 10, Epsilon: 0.11\n",
      "Episode: 436/500, Score: 130, Epsilon: 0.11\n",
      "Episode: 437/500, Score: 8, Epsilon: 0.11\n",
      "Episode: 438/500, Score: 110, Epsilon: 0.11\n",
      "Episode: 439/500, Score: 146, Epsilon: 0.11\n",
      "Episode: 440/500, Score: 262, Epsilon: 0.11\n",
      "Episode: 441/500, Score: 90, Epsilon: 0.11\n",
      "Episode: 442/500, Score: 252, Epsilon: 0.11\n",
      "Episode: 443/500, Score: 295, Epsilon: 0.11\n",
      "Episode: 444/500, Score: 230, Epsilon: 0.11\n",
      "Episode: 445/500, Score: 207, Epsilon: 0.11\n",
      "Episode: 446/500, Score: 214, Epsilon: 0.11\n",
      "Episode: 447/500, Score: 171, Epsilon: 0.11\n",
      "Episode: 448/500, Score: 114, Epsilon: 0.11\n",
      "Episode: 449/500, Score: 101, Epsilon: 0.11\n",
      "Episode: 450/500, Score: 186, Epsilon: 0.10\n",
      "Episode: 451/500, Score: 127, Epsilon: 0.10\n",
      "Episode: 452/500, Score: 128, Epsilon: 0.10\n",
      "Episode: 453/500, Score: 428, Epsilon: 0.10\n",
      "Episode: 454/500, Score: 9, Epsilon: 0.10\n",
      "Episode: 455/500, Score: 13, Epsilon: 0.10\n",
      "Episode: 456/500, Score: 188, Epsilon: 0.10\n",
      "Episode: 457/500, Score: 128, Epsilon: 0.10\n",
      "Episode: 458/500, Score: 159, Epsilon: 0.10\n",
      "Episode: 459/500, Score: 130, Epsilon: 0.10\n",
      "Episode: 460/500, Score: 158, Epsilon: 0.10\n",
      "Episode: 461/500, Score: 141, Epsilon: 0.10\n",
      "Episode: 462/500, Score: 149, Epsilon: 0.10\n",
      "Episode: 463/500, Score: 170, Epsilon: 0.10\n",
      "Episode: 464/500, Score: 89, Epsilon: 0.10\n",
      "Episode: 465/500, Score: 119, Epsilon: 0.10\n",
      "Episode: 466/500, Score: 137, Epsilon: 0.10\n",
      "Episode: 467/500, Score: 139, Epsilon: 0.10\n",
      "Episode: 468/500, Score: 140, Epsilon: 0.10\n",
      "Episode: 469/500, Score: 12, Epsilon: 0.10\n",
      "Episode: 470/500, Score: 100, Epsilon: 0.09\n",
      "Episode: 471/500, Score: 13, Epsilon: 0.09\n",
      "Episode: 472/500, Score: 92, Epsilon: 0.09\n",
      "Episode: 473/500, Score: 9, Epsilon: 0.09\n",
      "Episode: 474/500, Score: 137, Epsilon: 0.09\n",
      "Episode: 475/500, Score: 8, Epsilon: 0.09\n",
      "Episode: 476/500, Score: 10, Epsilon: 0.09\n",
      "Episode: 477/500, Score: 39, Epsilon: 0.09\n",
      "Episode: 478/500, Score: 66, Epsilon: 0.09\n",
      "Episode: 479/500, Score: 83, Epsilon: 0.09\n",
      "Episode: 480/500, Score: 11, Epsilon: 0.09\n",
      "Episode: 481/500, Score: 117, Epsilon: 0.09\n",
      "Episode: 482/500, Score: 126, Epsilon: 0.09\n",
      "Episode: 483/500, Score: 120, Epsilon: 0.09\n",
      "Episode: 484/500, Score: 127, Epsilon: 0.09\n",
      "Episode: 485/500, Score: 119, Epsilon: 0.09\n",
      "Episode: 486/500, Score: 172, Epsilon: 0.09\n",
      "Episode: 487/500, Score: 10, Epsilon: 0.09\n",
      "Episode: 488/500, Score: 109, Epsilon: 0.09\n",
      "Episode: 489/500, Score: 13, Epsilon: 0.09\n",
      "Episode: 490/500, Score: 11, Epsilon: 0.09\n",
      "Episode: 491/500, Score: 105, Epsilon: 0.09\n",
      "Episode: 492/500, Score: 110, Epsilon: 0.08\n",
      "Episode: 493/500, Score: 11, Epsilon: 0.08\n",
      "Episode: 494/500, Score: 10, Epsilon: 0.08\n",
      "Episode: 495/500, Score: 103, Epsilon: 0.08\n",
      "Episode: 496/500, Score: 11, Epsilon: 0.08\n",
      "Episode: 497/500, Score: 9, Epsilon: 0.08\n",
      "Episode: 498/500, Score: 17, Epsilon: 0.08\n",
      "Episode: 499/500, Score: 113, Epsilon: 0.08\n"
     ]
    }
   ],
   "source": [
    "output_dir = './cartpole_model/'\n",
    "\n",
    "# Initialize the Agent\n",
    "agent = Agent(state_size, action_size, gamma=gamma, epsilon=epsilon, epsilon_min=epsilon_min, epsilon_decay=epsilon_decay, learning_rate=learning_rate)\n",
    "done = False\n",
    "\n",
    "# Main Script\n",
    "for e in range(n_episodes):\n",
    "    state = env.reset()[0]\n",
    "    state = np.reshape(state, [1, state_size])\n",
    "    total_reward = 0\n",
    "\n",
    "    for time_t in range(500):\n",
    "        action = agent.act(state[0])\n",
    "        next_state, reward, done, truncated, _ = env.step(action)\n",
    "        done = done or truncated\n",
    "        next_state = np.reshape(next_state, [1, state_size])\n",
    "        agent.remember(state[0], action, reward, next_state[0], done)\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "\n",
    "        if done:\n",
    "            print(f\"Episode: {e}/{n_episodes}, Score: {time_t}, Epsilon: {agent.epsilon:.2f}\")\n",
    "            break\n",
    "\n",
    "    if len(memory) > batch_size:\n",
    "        loss = agent.replay(batch_size)\n",
    "\n",
    "    # Update epsilon\n",
    "    if agent.epsilon > agent.epsilon_min:\n",
    "        agent.epsilon *= agent.epsilon_decay\n",
    "\n",
    "    # Update target network\n",
    "    if e % update_target_every == 0:\n",
    "        agent.update_target_model()\n",
    "\n",
    "    \n",
    "    if e % 100 == 0:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        agent.save_model(os.path.join(output_dir, f'model_{e}.keras'))\n",
    "\n",
    "agent.save_model(os.path.join(output_dir, f'model_500.keras'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dd65670f-d259-4135-ba24-d1ba2901a2d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium[classic-control] in e:\\coding_dir\\anaconda\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in e:\\coding_dir\\anaconda\\lib\\site-packages (from gymnasium[classic-control]) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in e:\\coding_dir\\anaconda\\lib\\site-packages (from gymnasium[classic-control]) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in e:\\coding_dir\\anaconda\\lib\\site-packages (from gymnasium[classic-control]) (4.11.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in e:\\coding_dir\\anaconda\\lib\\site-packages (from gymnasium[classic-control]) (0.0.4)\n",
      "Requirement already satisfied: pygame>=2.1.3 in e:\\coding_dir\\anaconda\\lib\\site-packages (from gymnasium[classic-control]) (2.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"gymnasium[classic-control]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1355c6b9-df6f-4241-9662-fe27e8923756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1 reward: 386.0\n",
      "Episode 2 reward: 386.0\n",
      "Episode 3 reward: 300.0\n",
      "Episode 4 reward: 318.0\n",
      "Episode 5 reward: 500.0\n"
     ]
    }
   ],
   "source": [
    "def render_episode(agent, model_path, num_episodes=1):\n",
    "    \n",
    "    agent.load_model(model_path)\n",
    "    \n",
    "    env = gym.make('CartPole-v1', render_mode='human')\n",
    "    for episode in range(num_episodes):\n",
    "        state,_ = env.reset()\n",
    "        state = state.reshape(1, -1)\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "        while not done:\n",
    "            env.render()\n",
    "            action = agent.act(state)\n",
    "            next_state, reward, done, truncated, _ = env.step(action)\n",
    "            next_state = next_state.reshape(1, -1)\n",
    "            total_reward += reward\n",
    "            state = next_state\n",
    "            if truncated:\n",
    "                done = True\n",
    "        print(f\"Episode {episode + 1} reward: {total_reward}\")\n",
    "    env.close()\n",
    "\n",
    "\n",
    "state_size = 4\n",
    "action_size = 2\n",
    "agent = Agent(state_size, action_size)\n",
    "agent.epsilon = 0.0  \n",
    "\n",
    "\n",
    "model_path = \"./cartpole_model/model_300.keras\"\n",
    "render_episode(agent, model_path, num_episodes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51375f1-f976-4139-9fd9-b757198c2770",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
